{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/huggingface/transformers/archive/refs/heads/master.zip\n",
      "Error converting file:  transformers-main/tests/fixtures/test_sentencepiece_bpe.model\n",
      "Error converting file:  transformers-main/tests/fixtures/spiece.model\n",
      "Error converting file:  transformers-main/tests/fixtures/test_sentencepiece_bpe_char.model\n",
      "Error converting file:  transformers-main/tests/fixtures/test_sentencepiece_no_bos.model\n",
      "Error converting file:  transformers-main/tests/fixtures/test_sentencepiece.model\n",
      "Error converting file:  transformers-main/tests/fixtures/test_sentencepiece_with_bytefallback.model\n",
      "Exiting: Cleaning up .chroma directory\n",
      "Error converting file:  transformers-main/examples/legacy/seq2seq/test_data/wmt_en_ro/val.len\n",
      "Error converting file:  transformers-main/examples/legacy/seq2seq/test_data/wmt_en_ro/train.len\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "\n",
    "\n",
    "# Replace with the repository URL you want to download\n",
    "repo_url = \"https://github.com/user/repo.git\"\n",
    "output_pdf = \"output.pdf\"\n",
    "from PyPDF2 import PdfFileReader, PdfFileWriter\n",
    "import PyPDF2\n",
    "from io import BytesIO\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate,Preformatted\n",
    "from reportlab.platypus import Image  as RLImage\n",
    "from reportlab.platypus import Paragraph, Spacer\n",
    "\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.utils import ImageReader\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def download_repo_zip(link, output_folder = \"main.zip\"):\n",
    "    username =  link.split('/')[3]\n",
    "    repo = link.split('/')[4]\n",
    "    # zip_url = f\"https://github.com/{username}/{repo}/archive/refs/heads/main.zip\"\n",
    "    zip_url = f\"https://github.com/{username}/{repo}/archive/refs/heads/master.zip\"\n",
    "    print(zip_url)\n",
    "\n",
    "    response = requests.get(zip_url)\n",
    "    response.raise_for_status()\n",
    "    #down load the zip file\n",
    "    with open('main.zip', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    # return BytesIO(response.content)\n",
    "\n",
    "def extract_zip(zip_file, destination_folder):\n",
    "    with zipfile.ZipFile(zip_file) as zf:\n",
    "        zf.extractall(destination_folder)\n",
    "    #get the name of the extracted folder\n",
    "    folder_name = zf.namelist()[0]\n",
    "    return folder_name\n",
    "\n",
    "def convert_to_pdf(input_path, output_path):\n",
    "    if input_path.endswith(\".pdf\"):\n",
    "        # Create a new PDF with the file path heading\n",
    "        buffer = BytesIO()\n",
    "        doc = SimpleDocTemplate(buffer, pagesize=letter)\n",
    "        styles = getSampleStyleSheet()\n",
    "        elements = []\n",
    "        heading = Paragraph(f\"File path: {input_path}\", styles[\"Heading2\"])\n",
    "        elements.append(heading)\n",
    "        elements.append(Spacer(1, 12))\n",
    "        doc.build(elements)\n",
    "\n",
    "        # Read the newly created PDF with heading\n",
    "        buffer.seek(0)\n",
    "        new_pdf = PdfFileReader(buffer)\n",
    "\n",
    "        # Read the input PDF\n",
    "        with open(input_path, \"rb\") as f:\n",
    "            input_pdf = PdfFileReader(f)\n",
    "\n",
    "        # Merge the new PDF with heading and the input PDF\n",
    "        pdf_writer = PdfFileWriter()\n",
    "        for page_num in range(new_pdf.getNumPages()):\n",
    "            pdf_writer.addPage(new_pdf.getPage(page_num))\n",
    "\n",
    "        for page_num in range(input_pdf.getNumPages()):\n",
    "            pdf_writer.addPage(input_pdf.getPage(page_num))\n",
    "\n",
    "        # Save the merged PDF to the output file\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            pdf_writer.write(f)\n",
    "\n",
    "    elif input_path.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\", \".tiff\")):\n",
    "        img = Image.open(input_path)\n",
    "        img_reader = ImageReader(img)\n",
    "        img_width, img_height = img.size\n",
    "        aspect_ratio = img_height / img_width\n",
    "\n",
    "\n",
    "        max_pdf_width = letter[0] - 2 * 72  # 1 inch margin on each side\n",
    "        max_pdf_height = letter[1] - 2 * 72  # 1 inch margin on top and bottom\n",
    "\n",
    "        if img_width > max_pdf_width:\n",
    "                img_width = max_pdf_width\n",
    "                img_height = img_width * aspect_ratio\n",
    "        if img_height > max_pdf_height:\n",
    "            img_height = max_pdf_height\n",
    "            img_width = img_height / aspect_ratio\n",
    "        img_width = int(img_width)\n",
    "        img_height = int(img_height)\n",
    "        # Resize the image\n",
    "        img = img.resize((int(img_width), int(img_height)))\n",
    "\n",
    "        img = img.resize((int(img_width), int(img_height)))\n",
    " \n",
    "        img.save(output_path, \"PNG\")\n",
    "        # Create a new PDF with the image\n",
    "        doc = SimpleDocTemplate(output_path, pagesize=letter)\n",
    "        styles = getSampleStyleSheet()\n",
    "\n",
    "        elements = []\n",
    "        heading = Paragraph(f\" {input_path}\", styles[\"Heading2\"])\n",
    "        elements.append(heading)\n",
    "        elements.append(Spacer(1, 12))\n",
    "\n",
    "        img_rl = RLImage(input_path, width=img_width, height=img_height, kind='proportional')\n",
    "        elements.append(img_rl)\n",
    "\n",
    "        doc.build(elements)\n",
    "\n",
    "    else:\n",
    "        with open(input_path, \"r\") as f:\n",
    "            content = f.read()\n",
    "   \n",
    "        doc = SimpleDocTemplate(output_path, pagesize=letter)\n",
    "        styles = getSampleStyleSheet()\n",
    "        elements = []\n",
    "\n",
    "        # Add the file path heading\n",
    "        heading = Paragraph(f\"{input_path}\", styles[\"Heading2\"])\n",
    "        elements.append(heading)\n",
    "        elements.append(Spacer(1, 12))\n",
    "\n",
    "        # Add the content as Preformatted text\n",
    "        text = Preformatted(content, style=styles[\"Code\"])\n",
    "        elements.append(text)\n",
    "\n",
    "        doc.build(elements)\n",
    "\n",
    "def merge_pdfs(pdf_files, output_path):\n",
    "    pdf_writer = PyPDF2.PdfWriter()\n",
    "    for pdf_file in pdf_files:\n",
    "        with open(pdf_file, \"rb\") as f:\n",
    "            try:\n",
    "                pdf_reader = PyPDF2.PdfReader(f)\n",
    "                if pdf_reader.is_encrypted:\n",
    "                    print(f\"{pdf_file} is encrypted. Skipping.\")\n",
    "                    continue\n",
    "            except:\n",
    "                print(f\"{pdf_file} is not a valid PDF. Skipping.\")\n",
    "                continue\n",
    "      \n",
    "                    \n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                pdf_writer.add_page(pdf_reader.pages[page_num])\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        pdf_writer.write(f)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    download_repo_zip('https://github.com/huggingface/transformers')\n",
    "    folder_name = extract_zip('./main.zip', './')\n",
    "    ingnore_list = ['__pycache__',]\n",
    "    pdf_files = []\n",
    "    for root, dirs, files in os.walk(folder_name):\n",
    "        for file in files:\n",
    "            \n",
    "            input_file = os.path.join(root, file)\n",
    "            #if the file contains any of the strings in the ignore list, skip it\n",
    "            if any(x in input_file for x in ingnore_list):\n",
    "                continue\n",
    "            #create a temp folder to store the pdf files\n",
    "            os.makedirs(\"temp\", exist_ok=True)\n",
    "            output_file = os.path.join(\"temp\", os.path.splitext(file)[0] + \".pdf\")\n",
    "\n",
    "            try:\n",
    "                convert_to_pdf(input_file, output_file)\n",
    "            except:\n",
    "                print(\"Error converting file: \", input_file)\n",
    "                continue\n",
    "            pdf_files.append(output_file)\n",
    "\n",
    "    merged_pdf = \"merged.pdf\"\n",
    "\n",
    "    merge_pdfs(pdf_files, merged_pdf)\n",
    "    #clean up the temp folder and downloaded zip file\n",
    "    os.remove(\"main.zip\")\n",
    "    shutil.rmtree(folder_name)\n",
    "    shutil.rmtree(\"temp\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.indexes.vectorstore import VectorstoreIndexCreator\n",
    "from langchain.chains import VectorDBQA\n",
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "\n",
    "# loader = UnstructuredPDFLoader(\"merged.pdf\")\n",
    "# pages = loader.load_and_split()\n",
    "# index = VectorstoreIndexCreator(vectorstore_cls = FAISS).from_loaders([loader])\n",
    "# index = VectorstoreIndexCreator(vectorstore_cls = FAISS)\n",
    "# index.vectorstore.load_local('asd.json')\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = FAISS.load_local('asd.json',embeddings =embeddings)\n",
    "qa =VectorDBQA.from_chain_type(llm =OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"), chain_type = \"stuff\",vectorstore = vectorstore )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.vectorstore.save_local('asd.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'duckdb.DuckDBPyConnection' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mindex.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 5\u001b[0m     pickle\u001b[39m.\u001b[39mdump(index, f)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'duckdb.DuckDBPyConnection' object"
     ]
    }
   ],
   "source": [
    "# index.vectorstore.save_local(\"index\")\n",
    "#save the index to a local file pkl \n",
    "import pickle\n",
    "with open(\"index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This repository is for a novel approach for high-fidelity image inpainting called MISF (Multi-level Interactive Siamese Filtering). It uses a single predictive network to conduct predictive filtering at the image level and deep feature level simultaneously, leading to high-fidelity inpainting results. The method outperforms state-of-the-art methods on three public datasets. The repository includes code for training and testing the model, as well as pretrained models and datasets.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run('what is this repo for ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To use this code, follow these steps:\n",
       "\n",
       "1. Download the necessary datasets (Places2, CelebA, and Dunhuang) and place them in the appropriate folders as specified in the code.\n",
       "\n",
       "2. Download the mask file and place it in the appropriate folder as specified in the code.\n",
       "\n",
       "3. Run the `data_list.py` script to generate the data list.\n",
       "\n",
       "4. Train the model using the `train.py` script and the parameters specified in the `config.yml` file.\n",
       "\n",
       "5. Test the model using the `test.py` script and the parameters specified in the `config.yml` file.\n",
       "\n",
       "Note that you will need Python 3.7 and PyTorch 1.0 or higher to run this code."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(qa.run('How can I use this. Example code ? Step by step')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To use the Experiment Tracking feature with Accelerate, you can follow these steps:\n",
       "\n",
       "1. Make sure you have the necessary experiment trackers installed, such as Weights and Biases, TensorBoard, or CometML.\n",
       "2. Add the `with_tracking` argument at the end of your command for starting the python script, such as `accelerate launch ./tracking.py --with_tracking`.\n",
       "3. In your script, use `Accelerate.init_trackers` to initialize the experiment trackers, and `Accelerator.log` to log your experiment metrics.\n",
       "4. Run your script as usual, and the experiment metrics will be automatically tracked by the experiment trackers you have installed."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(qa.run('how can I use this Experiment trackers ? Step by step')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To perform gradient accumulation with Accelerate, you can use the `Accelerator.accumulate` function and specify a `gradient_accumulation_steps` parameter. This will automatically handle gradient synchronization, check if the step should be performed, and auto-scale the loss. Here is an example code snippet:\n",
       "\n",
       "```\n",
       "accelerator = Accelerator(gradient_accumulation_steps=2)\n",
       "\n",
       "model, optimizer, training_dataloader = accelerator.prepare(model, optimizer, training_dataloader)\n",
       "\n",
       "for input, label in training_dataloader:\n",
       "    with accelerator.accumulate(model):\n",
       "        predictions = model(input)\n",
       "        loss = loss_function(predictions, label)\n",
       "        accelerator.backward(loss)\n",
       "        optimizer.step()\n",
       "        scheduler.step()\n",
       "        optimizer.zero_grad()\n",
       "```\n",
       "\n",
       "Note that this is just an example and you may need to adjust the code to fit your specific use case."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# qa.run('how can I Performing gradient accumulation with Accelerate? Step by step')\n",
    "# repogpt.init_agent('https://github.com/tsingqguo/misf',api_key='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')\n",
    "https://github.com/tsingqguo/misf\n",
    "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\n",
    "#jupyter note book show markdown\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "display(Markdown(qa.run('how can I Performing gradient accumulation with Accelerate? Step by step?')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import zipfile\n",
    "from PyPDF2 import PdfFileReader, PdfFileWriter\n",
    "import PyPDF2\n",
    "from io import BytesIO\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate,Preformatted\n",
    "from reportlab.platypus import Image  as RLImage\n",
    "from reportlab.platypus import Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.utils import ImageReader\n",
    "from PIL import Image\n",
    "import os\n",
    "from langchain.indexes.vectorstore import VectorstoreIndexCreator\n",
    "from langchain.chains import VectorDBQA,VectorDBQAWithSourcesChain\n",
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from flask import send_file\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "class REPOGPT:\n",
    "    def __init__(self) -> None:\n",
    "        \n",
    "        self.repo_link = None\n",
    "        self.api_key = None\n",
    "\n",
    "    def init_agent(self, api_key, repo_link = None,  load_vectorstore = None):\n",
    "        try:\n",
    "            os.remove('merged.pdf')\n",
    "        except:\n",
    "            pass\n",
    "        self.repo_link = repo_link\n",
    "        self.api_key = api_key\n",
    "        self.load_vectorstore = load_vectorstore\n",
    "        #assert if api key is valid\n",
    "        assert self.api_key != None, \"You need to provide an API key\"\n",
    "        self.REPOGPT_Initialized()\n",
    "        return gr.update(visible = True),'Initialize Finished'\n",
    "\n",
    "\n",
    "\n",
    "    def REPOGPT_Initialized(self,image_included = False):\n",
    "\n",
    "        \n",
    "        os.environ[\"OPENAI_API_KEY\"] = self.api_key\n",
    "        if self.load_vectorstore == None:\n",
    "            loader = UnstructuredPDFLoader( self.create_repo_pdf(self.repo_link,image_included = image_included))\n",
    "            # pages = loader.load_and_split()\n",
    "            self.index = VectorstoreIndexCreator(vectorstore_cls = FAISS).from_loaders([loader])\n",
    "            self.vectorstore = self.index.vectorstore\n",
    "            print(' vectorstore created')\n",
    "        else:\n",
    "            embeddings = OpenAIEmbeddings()\n",
    "            self.vectorstore = FAISS.load_local(self.load_vectorstore,embeddings =embeddings)\n",
    "            print(' vectorstore loaded')\n",
    "\n",
    "        self.qa = VectorDBQA.from_chain_type(llm =OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"), chain_type = \"stuff\",vectorstore = self.vectorstore )\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "    def download_repo_zip(self, link, output_folder = \"main.zip\"):\n",
    "        username =  link.split('/')[3]\n",
    "        repo = link.split('/')[4]\n",
    "        zip_url = f\"https://github.com/{username}/{repo}/archive/refs/heads/master.zip\"\n",
    "        self.zip_url = zip_url\n",
    "        response = requests.get(zip_url)\n",
    "        response.raise_for_status()\n",
    "        #down load the zip file\n",
    "        with open('main.zip', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        # return the name of the extracted folder\n",
    "        # return self.extract_zip(\"main.zip\", output_folder)\n",
    "        # return BytesIO(response.content)\n",
    "\n",
    "    def extract_zip(self, zip_file, destination_folder):\n",
    "        with zipfile.ZipFile(zip_file) as zf:\n",
    "            zf.extractall(destination_folder)\n",
    "        #get the name of the extracted folder\n",
    "        folder_name = zf.namelist()[0]\n",
    "        return folder_name\n",
    "\n",
    "    def convert_to_pdf(self, input_path, output_path):\n",
    "        if input_path.endswith(\".pdf\"):\n",
    "            # Create a new PDF with the file path heading\n",
    "            buffer = BytesIO()\n",
    "            doc = SimpleDocTemplate(buffer, pagesize=letter)\n",
    "            styles = getSampleStyleSheet()\n",
    "            elements = []\n",
    "            heading = Paragraph(f\"File path: {input_path}\", styles[\"Heading2\"])\n",
    "            elements.append(heading)\n",
    "            elements.append(Spacer(1, 12))\n",
    "            doc.build(elements)\n",
    "\n",
    "            # Read the newly created PDF with heading\n",
    "            buffer.seek(0)\n",
    "            new_pdf = PdfFileReader(buffer)\n",
    "\n",
    "            # Read the input PDF\n",
    "            with open(input_path, \"rb\") as f:\n",
    "                input_pdf = PdfFileReader(f)\n",
    "\n",
    "            # Merge the new PDF with heading and the input PDF\n",
    "            pdf_writer = PdfFileWriter()\n",
    "            for page_num in range(new_pdf.getNumPages()):\n",
    "                pdf_writer.addPage(new_pdf.getPage(page_num))\n",
    "\n",
    "            for page_num in range(input_pdf.getNumPages()):\n",
    "                pdf_writer.addPage(input_pdf.getPage(page_num))\n",
    "\n",
    "            # Save the merged PDF to the output file\n",
    "            with open(output_path, \"wb\") as f:\n",
    "                pdf_writer.write(f)\n",
    "\n",
    "        elif input_path.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\", \".tiff\")):\n",
    "            img = Image.open(input_path)\n",
    "            img_reader = ImageReader(img)\n",
    "            img_width, img_height = img.size\n",
    "            aspect_ratio = img_height / img_width\n",
    "\n",
    "\n",
    "            max_pdf_width = letter[0] - 2 * 72  # 1 inch margin on each side\n",
    "            max_pdf_height = letter[1] - 2 * 72  # 1 inch margin on top and bottom\n",
    "\n",
    "            if img_width > max_pdf_width:\n",
    "                    img_width = max_pdf_width\n",
    "                    img_height = img_width * aspect_ratio\n",
    "            if img_height > max_pdf_height:\n",
    "                img_height = max_pdf_height\n",
    "                img_width = img_height / aspect_ratio\n",
    "            img_width = int(img_width)\n",
    "            img_height = int(img_height)\n",
    "            # Resize the image\n",
    "            img = img.resize((int(img_width), int(img_height)))\n",
    "\n",
    "            img = img.resize((int(img_width), int(img_height)))\n",
    "    \n",
    "            img.save(output_path, \"PNG\")\n",
    "            # Create a new PDF with the image\n",
    "            doc = SimpleDocTemplate(output_path, pagesize=letter)\n",
    "            styles = getSampleStyleSheet()\n",
    "\n",
    "            elements = []\n",
    "            heading = Paragraph(f\" {input_path}\", styles[\"Heading2\"])\n",
    "            elements.append(heading)\n",
    "            elements.append(Spacer(1, 12))\n",
    "\n",
    "            img_rl = RLImage(input_path, width=img_width, height=img_height, kind='proportional')\n",
    "            elements.append(img_rl)\n",
    "\n",
    "            doc.build(elements)\n",
    "\n",
    "        else:\n",
    "            with open(input_path, \"r\") as f:\n",
    "                content = f.read()\n",
    "    \n",
    "            doc = SimpleDocTemplate(output_path, pagesize=letter)\n",
    "            styles = getSampleStyleSheet()\n",
    "            elements = []\n",
    "\n",
    "            # Add the file path heading\n",
    "            heading = Paragraph(f\"{input_path}\", styles[\"Heading2\"])\n",
    "            elements.append(heading)\n",
    "            elements.append(Spacer(1, 12))\n",
    "\n",
    "            # Add the content as Preformatted text\n",
    "            text = Preformatted(content, style=styles[\"Code\"])\n",
    "            elements.append(text)\n",
    "\n",
    "            doc.build(elements)\n",
    "\n",
    "    def merge_pdfs(self, pdf_files, output_path):\n",
    "        pdf_writer = PyPDF2.PdfWriter()\n",
    "        for pdf_file in pdf_files:\n",
    "            with open(pdf_file, \"rb\") as f:\n",
    "                try:\n",
    "                    pdf_reader = PyPDF2.PdfReader(f)\n",
    "                    if pdf_reader.is_encrypted:\n",
    "                        print(f\"{pdf_file} is encrypted. Skipping.\")\n",
    "                        continue\n",
    "                except:\n",
    "                    print(f\"{pdf_file} is not a valid PDF. Skipping.\")\n",
    "                    continue\n",
    "        \n",
    "                        \n",
    "                for page_num in range(len(pdf_reader.pages)):\n",
    "                    pdf_writer.add_page(pdf_reader.pages[page_num])\n",
    "\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            pdf_writer.write(f)\n",
    "\n",
    "    def get_pdf(self):\n",
    "        return self.merged_pdf_path\n",
    "\n",
    "    def save_indexDB(self,save_path = 'indexDB.json'):\n",
    "        self.vectorstore.save_local(save_path)\n",
    "        print(\"indexDB saved at: \", save_path)\n",
    "\n",
    "   \n",
    "\n",
    "    def create_repo_pdf(self, repo_link, image_included = False,  merged_pdf = \"temp_merged.pdf\"):\n",
    "        self.merged_pdf_path = merged_pdf\n",
    "        self.download_repo_zip(repo_link)\n",
    "        folder_name = self.extract_zip('./main.zip', './')\n",
    "        ingnore_list = ['__pycache__',]\n",
    "        if not image_included:\n",
    "            ingnore_list.append('.jpg')\n",
    "            ingnore_list.append('.png')\n",
    "            ingnore_list.append('.jpeg')\n",
    "            ingnore_list.append('.gif')\n",
    "            ingnore_list.append('.bmp')\n",
    "            ingnore_list.append('.tiff')\n",
    "\n",
    "        print('folder_name: ', folder_name)\n",
    "        pdf_files = []\n",
    "        for root, dirs, files in os.walk(folder_name):\n",
    "            for file in files:\n",
    "                \n",
    "                input_file = os.path.join(root, file)\n",
    "                #if the file contains any of the strings in the ignore list, skip it\n",
    "                if any(x in input_file for x in ingnore_list):\n",
    "                    continue\n",
    "                #create a temp folder to store the pdf files\n",
    "                os.makedirs(\"temp\", exist_ok=True)\n",
    "                output_file = os.path.join(\"temp\", os.path.splitext(file)[0] + \".pdf\")\n",
    "\n",
    "                try:\n",
    "                    self.convert_to_pdf(input_file, output_file)\n",
    "                except:\n",
    "                    print(\"Error converting file: \", input_file)\n",
    "                    continue\n",
    "                pdf_files.append(output_file)\n",
    "\n",
    "        \n",
    "\n",
    "        self.merge_pdfs(pdf_files, self.merged_pdf_path)\n",
    "        #clean up the temp folder and downloaded zip file\n",
    "        os.remove(\"main.zip\")\n",
    "        shutil.rmtree(folder_name)\n",
    "        shutil.rmtree(\"temp\")\n",
    "\n",
    "        return self.merged_pdf_path\n",
    "\n",
    "\n",
    "    def Answer_quetsion(self, question):\n",
    "        return self.qa.run(question)\n",
    "        \n",
    "    def Answer_quetsion_with_source(self, question):\n",
    "        return self.qa({\"question\": question}, return_only_outputs = True)\n",
    "\n",
    "\n",
    "\n",
    "def call_output(string = 'REPOGPT Initializing'):\n",
    "    return string\n",
    "\n",
    "def download_file(filename = 'merged.pdf'):\n",
    "    # filename = repogpt.get_pdf()\n",
    "    return send_file(filename, as_attachment=True)\n",
    "\n",
    "\n",
    "repogpt = REPOGPT()\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        gr.Markdown(\"<h3><center>REPOGPT</center></h3>\")\n",
    "        gr.Markdown(\n",
    "            \"\"\"This is a demo to the work [REPOGPT](https://github.com/wuchangsheng951/RepoGPT).<br>\n",
    "            This space connects ChatGPT and RepoGPT is a Python library that allows you to search and answer questions about a GitHub repository's content.<br>  \n",
    "            \"\"\"\n",
    "        )\n",
    "    with gr.Row():\n",
    "        apikey = gr.Textbox(\n",
    "            placeholder=\"Paste your OpenAI API key here to start Visual ChatGPT(sk-...) and press Enter ↵️\",\n",
    "            show_label=True,\n",
    "            label = 'OpenAI API key',\n",
    "            lines=1,\n",
    "            type=\"password\",\n",
    "        )\n",
    "    with gr.Row():\n",
    "        repo_link = gr.Textbox(\n",
    "            placeholder=\"Paste your repo_link and press Enter ↵️\",\n",
    "            label = 'repo_link',\n",
    "\n",
    "            show_label=True,\n",
    "            lines=1,\n",
    "        )    \n",
    "\n",
    "    with gr.Column(scale=0.7):\n",
    "            Initialize = gr.Button(\"Initialize RepoGPT\")\n",
    "\n",
    "    output = gr.Textbox(label=\"Output Box\")\n",
    "\n",
    "    with gr.Row(visible=False) as input_raws:\n",
    "        with gr.Column(scale=0.7):\n",
    "            txt = gr.Textbox(show_label=False, placeholder=\"Enter your question\").style(container=False)\n",
    "\n",
    "        with gr.Column(scale=0.4):\n",
    "            AQ = gr.Button(\"Ask a Question\").style(container=False)\n",
    "\n",
    "        # with gr.Row():\n",
    "        #     Download = gr.Button(\"Download PDF\")\n",
    "\n",
    "\n",
    "    gr.Examples(\n",
    "        examples=[\"Whats the name of this repo?\",\n",
    "                  \"Whats this repo for?\",\n",
    "                  \"How can I use this. Example code ? Step by step\",\n",
    "                  \"how can I use this Experiment trackers ? Step by step\",\n",
    "                  \"how can I Performing gradient accumulation with Accelerate? Step by step?\",\n",
    "                  \"Make it like water-color painting\",\n",
    "                  \"What is the background color\",\n",
    "                  \"Describe this image\",\n",
    "                  \"please detect the depth of this image\",\n",
    "                  \"Can you use this depth image to generate a cute dog\",\n",
    "                  ],\n",
    "        inputs=txt\n",
    "    )\n",
    "\n",
    "    apikey.submit(repogpt.init_agent, [apikey,repo_link], [input_raws, output])\n",
    "    Initialize.click(repogpt.init_agent, [apikey,repo_link], [input_raws, output])\n",
    "    apikey.submit(call_output, [],[output])\n",
    "    txt.submit(repogpt.Answer_quetsion, [txt], [output])\n",
    "    AQ.click(repogpt.Answer_quetsion, [txt], [output])\n",
    "    # Download.click(download_file, [], [Download])\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder_name:  RepoGPT-main/\n",
      " vectorstore created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'visible': True, '__type__': 'generic_update'}, 'Initialize Finished')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "repogpt.init_agent(api_key='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', repo_link='https://github.com/wuchangsheng951/RepoGPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The library allows you to search and answer questions about a GitHub repository's content using OpenAI's GPT-3.5-turbo."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(repogpt.Answer_quetsion('What is repo for ?')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To use this code, follow these steps:\\n\\n1. Download the necessary datasets (Places2, CelebA, and Dunhuang) and place them in the appropriate folders as specified in the code.\\n2. Download the mask file and place it in the appropriate folder as specified in the code.\\n3. Run the data_list.py script to generate the data list.\\n4. Train the model using the train.py script and the parameters specified in the config.yml file.\\n5. Test the model using the test.py script and the parameters specified in the config.yml file.\\n\\nNote that you will need Python 3.7 and PyTorch 1.0 or higher to run this code.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repogpt.Answer_quetsion('How to use this repo? step by step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Markdown expects text, not {'answer': 'To use RepoGPT, follow these steps: \\n1. Install the dependencies using \"pip install -r requirements.txt\"\\n2. Initialize the REPOGPT object using \"repogpt = REPOGPT()\"\\n3. Download the necessary datasets (Places2, CelebA, and Dunhuang) and place them in the appropriate folders as specified in the code.\\n4. Download the mask file and place it in the appropriate folder as specified in the code.\\n5. Run the data_list.py script to generate the data list.\\n6. Train the model using the train.py script and the parameters specified in the config.yml file.\\n7. Test the model using the test.py script and the parameters specified in the config.yml file.\\nNote that Python 3.7 and PyTorch 1.0 or higher are required to run this code. \\n', 'sources': 'merged.pdf'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m display(Markdown(repogpt\u001b[39m.\u001b[39mAnswer_quetsion_with_source(\u001b[39m'\u001b[39m\u001b[39mHow to use this repo? step by step\u001b[39m\u001b[39m'\u001b[39m)))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/display.py:328\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m {}\n\u001b[1;32m    327\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreload()\n\u001b[0;32m--> 328\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_data()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/display.py:395\u001b[0m, in \u001b[0;36mTextDisplayObject._check_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    394\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 395\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expects text, not \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata))\n",
      "\u001b[0;31mTypeError\u001b[0m: Markdown expects text, not {'answer': 'To use RepoGPT, follow these steps: \\n1. Install the dependencies using \"pip install -r requirements.txt\"\\n2. Initialize the REPOGPT object using \"repogpt = REPOGPT()\"\\n3. Download the necessary datasets (Places2, CelebA, and Dunhuang) and place them in the appropriate folders as specified in the code.\\n4. Download the mask file and place it in the appropriate folder as specified in the code.\\n5. Run the data_list.py script to generate the data list.\\n6. Train the model using the train.py script and the parameters specified in the config.yml file.\\n7. Test the model using the test.py script and the parameters specified in the config.yml file.\\nNote that Python 3.7 and PyTorch 1.0 or higher are required to run this code. \\n', 'sources': 'merged.pdf'}"
     ]
    }
   ],
   "source": [
    "display(Markdown(repogpt.Answer_quetsion_with_source('How to use this repo? step by step')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "There is no code provided for model initialization. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(repogpt.Answer_quetsion_with_source('model initialization ? can you show me the code ? step by step')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure, here is the code for the models.py file step by step:\n",
       "\n",
       "1. The first few lines import necessary modules and classes:\n",
       "\n",
       "```\n",
       "import os\n",
       "import torch\n",
       "import torch.nn as nn\n",
       "import torch.optim as optim\n",
       "from .networks import InpaintGenerator, Discriminator\n",
       "from .loss import AdversarialLoss, PerceptualLoss, StyleLoss\n",
       "```\n",
       "\n",
       "2. The next class defined is the `BaseModel` class, which is a subclass of `nn.Module`:\n",
       "\n",
       "```\n",
       "class BaseModel(nn.Module):\n",
       "    def __init__(self, name, config):\n",
       "        super(BaseModel, self).__init__()\n",
       "        self.name = name\n",
       "```\n",
       "\n",
       "3. The `InpaintingModel` class is defined as a subclass of `BaseModel`:\n",
       "\n",
       "```\n",
       "class InpaintingModel(BaseModel):\n",
       "    def __init__(self, config):\n",
       "        super(InpaintingModel, self).__init__('InpaintingModel', config)\n",
       "        self.generator = InpaintGenerator(config)\n",
       "        self.discriminator = Discriminator(config)\n",
       "        self.adversarial_loss = AdversarialLoss(config)\n",
       "        self.perceptual_loss = PerceptualLoss(config)\n",
       "        self.style_loss = StyleLoss(config)\n",
       "```\n",
       "\n",
       "4. The `InpaintingModel` class has several attributes, including `generator`, `discriminator`, `adversarial_loss`, `perceptual_loss`, and `style_loss`, which are all initialized with their respective classes from the `networks` and `loss` modules.\n",
       "\n",
       "5. The `InpaintingModel` class also has a `forward` method, which takes in an input image and generates an output image:\n",
       "\n",
       "```\n",
       "def forward(self, x, mask):\n",
       "    self.mask = mask\n",
       "    self.completed = self.generator(x, mask)\n",
       "    return self.completed\n",
       "```\n",
       "\n",
       "6. Finally, the `InpaintingModel` class has a `train` method, which trains the model using the specified loss functions and optimizer:\n",
       "\n",
       "```\n",
       "def train(self, train_loader, val_loader, config):\n",
       "    # define optimizer\n",
       "    optimizer_g = optim.Adam(self.generator.parameters(), lr=config.LR_G, betas=(config.BETA1, config.BETA2))\n",
       "    optimizer_d = optim.Adam(self.discriminator.parameters(), lr=config.LR_D, betas=(config.BETA1, config.BETA2))\n",
       "\n",
       "    # define loss functions\n",
       "    adversarial_loss = self.adversarial_loss\n",
       "    perceptual_loss = self.perceptual_loss\n",
       "    style_loss = self.style_loss\n",
       "\n",
       "    # train loop\n",
       "    for epoch in range(config.EPOCHS):\n",
       "        for i, (x, mask) in enumerate(train_loader):\n",
       "            self.iteration += 1\n",
       "\n",
       "            # set to train mode\n",
       "            self.generator.train()\n",
       "            self.discriminator.train()\n",
       "\n",
       "            # zero out gradients\n",
       "            optimizer_g.zero_grad()\n",
       "            optimizer_d.zero_grad()\n",
       "\n",
       "            # forward pass\n",
       "            completed = self.forward(x, mask)\n",
       "            real = x\n",
       "\n",
       "            # adversarial loss\n",
       "            d_real = self.discriminator(real, mask)\n",
       "            d_fake = self.discriminator(completed.detach(), mask)\n",
       "            loss_adv = adversarial_loss(d_real, d_fake)\n",
       "\n",
       "            # perceptual loss\n",
       "            loss_perc = perceptual_loss(completed, real)\n",
       "\n",
       "            # style loss\n",
       "            loss_style = style_loss(completed, real)\n",
       "\n",
       "            # total loss\n",
       "            loss_g = loss_adv + config.LAMBDA_P * loss_perc + config.LAMBDA_S * loss_style\n",
       "            loss_g.backward()\n",
       "            optimizer_g.step()\n",
       "\n",
       "            # discriminator loss\n",
       "            d_real = self.discriminator(real, mask)\n",
       "            d_fake = self.discriminator(completed.detach(), mask)\n",
       "            loss_d = adversarial_loss(d_real, d_fake)\n",
       "            loss_d.backward()\n",
       "            optimizer_d.step()\n",
       "\n",
       "            # print loss\n",
       "            if self.iteration % config.PRINT_FREQ == 0:\n",
       "                print('Epoch: [{0}][{1}/{2}] '\n",
       "                      'Loss_G: {loss_g:.4f} '\n",
       "                      'Loss_D: {loss_d:.4f} '\n",
       "                      'Loss_Adv: {loss_adv:.4f} '\n",
       "                      'Loss_Perc: {loss_perc:.4f} '\n",
       "                      'Loss_Style: {loss_style:.4f}'.format(epoch, i, len(train_loader),\n",
       "                                                            loss_g=loss_g.item(),\n",
       "                                                            loss_d=loss_d.item(),\n",
       "                                                            loss_adv=loss_adv.item(),\n",
       "                                                            loss_perc=loss_perc.item(),\n",
       "                                                            loss_style=loss_style.item()))\n",
       "\n",
       "        # validate and save model\n",
       "        if epoch % config.VAL_FREQ == 0:\n",
       "            self.validate(val_loader, config)\n",
       "            self.save(config)\n",
       "```\n",
       "\n",
       "This method includes the training loop, which iterates over the training data and calculates the loss for each batch. It also includes validation and model saving at specified intervals."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(repogpt.Answer_quetsion('the models.py ? can you show me the code ? step by step')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('langchain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2978cd2d86bc9abc2355df98255f1b515694a55973a58299a51240d58677b487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
